// supabase/functions/analyze-reviews/index.ts
import { admin, corsHeaders } from "../_shared/db.ts";
/** === OpenAI: Chat Completions API + Structured Outputs ===
 * Docs (oficial):
 * - Chat Completions: https://platform.openai.com/docs/api-reference/chat/create
 * - Structured Outputs: https://platform.openai.com/docs/guides/structured-outputs
 * - Rate limits: https://platform.openai.com/docs/guides/rate-limits
 * - Batch API (si luego lo us√°s): https://platform.openai.com/docs/api-reference/batch
 */ const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const OPENAI_URL = "https://api.openai.com/v1/chat/completions";
const OPENAI_MODEL = Deno.env.get("OPENAI_MODEL") ?? "gpt-4o-mini-2024-07-18";
const OPENAI_MAX_RETRIES = Number(Deno.env.get("OPENAI_MAX_RETRIES") ?? "5");
const OPENAI_BACKOFF_BASE_MS = Number(Deno.env.get("OPENAI_BACKOFF_BASE_MS") ?? "500");
const OPENAI_BACKOFF_MAX_MS = Number(Deno.env.get("OPENAI_BACKOFF_MAX_MS") ?? "8000");
// Pacing objetivo (basado en tier 2: 5000 RPM, 2M TPM)
// Usamos 80% del l√≠mite para dejar margen de seguridad
const OPENAI_TARGET_RPM = Number(Deno.env.get("OPENAI_TARGET_RPM") ?? "4000");
const OPENAI_TARGET_TPM = Number(Deno.env.get("OPENAI_TARGET_TPM") ?? "1600000");
// L√≠mites y tama√±os (optimizados para Tier 2 - balance velocidad/calidad)
const DEFAULT_ANALYZE_LIMIT = Number(Deno.env.get("ANALYZE_DEFAULT_LIMIT") ?? "10");
const MAX_ANALYZE_LIMIT = Number(Deno.env.get("ANALYZE_MAX_LIMIT") ?? "500");
const ANALYZE_BATCH_SIZE = Math.max(1, Number(Deno.env.get("ANALYZE_BATCH_SIZE") ?? "5"));
const MAX_PER_PROVIDER_RATIO = Math.max(0.1, Math.min(0.9, Number(Deno.env.get("ANALYZE_PROVIDER_RATIO") ?? "0.5")));
const MAX_REVIEW_TEXT_LENGTH = Number(Deno.env.get("ANALYZE_MAX_REVIEW_LENGTH") ?? "1200");
const MAX_OUTPUT_TOKENS = Number(Deno.env.get("ANALYZE_MAX_OUTPUT_TOKENS") ?? "4096"); // Aumentado para 5 an√°lisis completos
const POST_BATCH_DELAY_MS = Number(Deno.env.get("ANALYZE_POST_BATCH_DELAY_MS") ?? "50");
// DEBUG m√≠nimo sin exponer toda la key
console.log('ü§ñ OpenAI Config:', {
  hasApiKey: !!OPENAI_API_KEY,
  keyPrefix: OPENAI_API_KEY ? OPENAI_API_KEY.substring(0, 7) + '...' : 'MISSING',
  model: OPENAI_MODEL
});
// === JSON Schemas (Structured Outputs) ===
const analysisItemSchema = {
  type: "object",
  additionalProperties: false,
  properties: {
    review_id: {
      type: "string"
    },
    language: {
      type: "string"
    },
    sentiment: {
      type: "string",
      enum: [
        "positive",
        "neutral",
        "negative"
      ]
    },
    overall_score: {
      type: "number",
      minimum: 0,
      maximum: 1
    },
    overall_sentiment_confidence: {
      type: "number",
      minimum: 0,
      maximum: 1
    },
    gap_to_five: {
      type: "boolean"
    },
    gap_reasons: {
      type: "array",
      items: {
        type: "string"
      }
    },
    critical_flags: {
      type: "array",
      items: {
        type: "string",
        enum: [
          "higiene",
          "intoxicacion",
          "trato_agresivo",
          "fraude",
          "seguridad",
          "queja_recurrente"
        ]
      }
    },
    executive_summary: {
      type: "string"
    },
    action_items: {
      type: "array",
      items: {
        type: "string"
      }
    },
    staff_mentions: {
      type: "array",
      items: {
        type: "object",
        additionalProperties: false,
        properties: {
          detected_name: {
            type: "string"
          },
          role: {
            type: "string"
          },
          sentiment: {
            type: "string",
            enum: [
              "positive",
              "neutral",
              "negative"
            ]
          },
          evidence_span: {
            type: "string"
          }
        },
        required: [
          "detected_name",
          "role",
          "sentiment",
          "evidence_span"
        ]
      }
    },
    aspects: {
      type: "array",
      items: {
        type: "object",
        additionalProperties: false,
        properties: {
          aspect: {
            type: "string"
          },
          sub_aspect: {
            type: "string"
          },
          sentiment: {
            type: "string",
            enum: [
              "positive",
              "neutral",
              "negative"
            ]
          },
          evidence_spans: {
            type: "array",
            items: {
              type: "string"
            },
            description: "Array de citas textuales (‚â§20 palabras cada una) donde se menciona este aspecto. Si el mismo subtema aparece m√∫ltiples veces, incluir todas las evidencias aqu√≠."
          },
          severity: {
            type: "number",
            minimum: 1,
            maximum: 3
          },
          gap_to_five_contrib: {
            type: "number",
            minimum: 0,
            maximum: 1
          }
        },
        required: [
          "aspect",
          "sub_aspect",
          "sentiment",
          "evidence_spans",
          "severity",
          "gap_to_five_contrib"
        ]
      }
    }
  },
  required: [
    "review_id",
    "language",
    "sentiment",
    "overall_score",
    "overall_sentiment_confidence",
    "gap_to_five",
    "gap_reasons",
    "critical_flags",
    "executive_summary",
    "action_items",
    "staff_mentions",
    "aspects"
  ]
};
const batchResponseSchema = {
  name: "ReviewsBatchAnalysis",
  schema: {
    type: "object",
    additionalProperties: false,
    properties: {
      analyses: {
        type: "array",
        items: analysisItemSchema
      }
    },
    required: [
      "analyses"
    ]
  },
  strict: true
};
// === Prompt del sistema (ABSA restaurantes) ===
const SYSTEM_PROMPT = `
Sos un analista gastron√≥mico especializado en Argentina. Analiz√°s reviews de restaurantes argentinos.

CONTEXTO: Argentina, espa√±ol rioplatense. Entend√© modismos locales:

REGLA CR√çTICA - AN√ÅLISIS GRAMATICAL (Argentina):
Distinci√≥n entre SUSTANTIVO (persona) vs ADJETIVO (tama√±o):

CASO 1 - SUSTANTIVO = STAFF (persona del personal):
Cuando "chico/chica/chicos/chicas" act√∫a como SUSTANTIVO (con art√≠culo, es el sujeto):
  ‚úì "el chico muy atento" ‚Üí servicio/personal
  ‚úì "la chica que nos atendi√≥" ‚Üí servicio/personal
  ‚úì "los chicos son re copados" ‚Üí servicio/personal
  ‚úì "las chicas del lugar" ‚Üí servicio/personal
  ‚úì "un chico nos atendi√≥" ‚Üí servicio/personal

CASO 2 - ADJETIVO = TAMA√ëO (modifica un sustantivo de objeto/lugar):
Cuando "chico/chica" act√∫a como ADJETIVO (describe/modifica otro sustantivo):
  ‚úì "porci√≥n chica" ‚Üí comida/porciones (ADJETIVO modifica "porci√≥n")
  ‚úì "el plato chico" ‚Üí comida/porciones (ADJETIVO modifica "plato")
  ‚úì "lugar chico" ‚Üí ambiente/espacio (ADJETIVO modifica "lugar")
  ‚úì "local muy chico" ‚Üí ambiente/espacio (ADJETIVO modifica "local")
  ‚úì "es chico el lugar" ‚Üí ambiente/espacio (ADJETIVO predicativo)

CLAVE: Si hay un SUSTANTIVO (porci√≥n/plato/lugar/local) + chico/chica ‚Üí es TAMA√ëO
        Si NO hay sustantivo y "el/la/los/las chico/a/s" es el sujeto ‚Üí es STAFF

Otros modismos:
- "copado", "genial", "b√°rbaro", "re bueno" = muy positivo
- "piola", "zaf√≥", "safable" = aceptable/pasable
- "una bosta", "mal√≠simo", "horrible" = muy negativo
- "rico" = sabroso/delicioso

CAMPOS REQUERIDOS:
- language: c√≥digo ISO (mayormente 'es' para espa√±ol)
- sentiment: global (positive/neutral/negative)
- overall_score: 0-1 (0=muy cr√≠tico, 1=muy entusiasta)
- overall_sentiment_confidence: 0-1 (certeza del an√°lisis)
- gap_to_five: true si rating ‚â•4‚òÖ o positivo PERO menciona mejoras concretas
- gap_reasons: mejoras espec√≠ficas mencionadas (m√°ximo 3)
- critical_flags: problemas graves (higiene, intoxicacion, trato_agresivo, fraude, seguridad, queja_recurrente)
- executive_summary: resumen ejecutivo ‚â§260 caracteres
- action_items: 1-3 acciones concretas recomendadas para mejora

Staff mentions (array) - Detecta empleados mencionados por nombre:
- detected_name: nombre exacto como aparece (ej: "Mar√≠a", "Juan P√©rez", "el Chef Carlos")
- role: rol/puesto si se menciona (mesero, hostess, chef, bartender, gerente, etc). Si no se menciona, usar string vac√≠o ""
- sentiment: positivo/neutral/negativo EN ESE CONTEXTO espec√≠fico
- evidence_span: cita exacta <=25 palabras donde se menciona
IMPORTANTE: Solo incluir personas reales del staff mencionadas por nombre (no "el mesero" o "la cajera" sin nombre).
Detecta variaciones: Mar√≠a/Mari/Mar√≠, Juan/Juanito, etc.

Aspects (array):
- aspect: CATEGORIA PRINCIPAL (servicio, comida, precio, ambiente, limpieza, porciones, etc)
- sub_aspect: DESCRIPTOR ESPEC√çFICO en snake_case que agrega valor diferenciador
- sentiment: del aspecto
- evidence_spans: ARRAY de citas (<=20 palabras cada una). Si el mismo sub_aspect aparece m√∫ltiples veces en la rese√±a, NO crear entradas duplicadas - en su lugar, agregar TODAS las menciones/evidencias en este array
- severity: 1-3 (severidad general del aspecto, considerando todas las menciones)
- gap_to_five_contrib: 0-1 (contribuci√≥n general considerando todas las menciones)

REGLAS CR√çTICAS PARA SUB-ASPECTOS:

0. NO DUPLICAR SUB-ASPECTOS: Si el mismo sub_aspect se menciona varias veces en una rese√±a, crear UNA SOLA entrada en el array aspects con TODAS las evidencias en evidence_spans. Por ejemplo:
   ‚úì CORRECTO: {aspect: "servicio", sub_aspect: "personal", evidence_spans: ["el chico muy atento", "la chica que nos atendi√≥ s√∫per amable"], sentiment: "positive"}
   ‚úó INCORRECTO: DOS entradas separadas del mismo servicio/personal

1. CONSOLIDA sin√≥nimos y conceptos similares en UN SOLO sub-aspecto GENERAL:
   ‚úì "atenci√≥n", "amabilidad", "trato", "cordialidad", "los chicos" ‚Üí personal
   ‚úì "r√°pido", "lento", "espera", "demora", "eficiente" ‚Üí velocidad
   ‚úì "rico", "sabroso", "delicioso", "mal sabor" ‚Üí sabor
   ‚úó NO crear sub-aspectos ultra-espec√≠ficos: "atencion_buena", "trato_amable", "velocidad_rapida" (redundante)

2. INTERPRET√Å CONTEXTO usando AN√ÅLISIS GRAMATICAL (Argentina):
   
   PRIORIDAD: Detect√° si "chico/chica" es SUSTANTIVO o ADJETIVO:
   
   ‚úì SUSTANTIVO (sujeto de la oraci√≥n) ‚Üí STAFF (persona)
     "el chico", "la chica", "los chicos", "las chicas", "un chico nos atendi√≥"
     ‚Üí aspect: servicio, sub_aspect: personal
   
   ‚úì ADJETIVO (modifica otro sustantivo) ‚Üí TAMA√ëO (objeto/lugar/comida)
     "porci√≥n chica", "el plato chico", "lugar chico", "local chico"
     ‚Üí aspect: comida/porciones O ambiente/espacio (seg√∫n qu√© modifica)
   
   Otros t√©rminos de tama√±o:
   ‚úì "porci√≥n grande/abundante/generosa" ‚Üí comida/porciones
   ‚úì "lugar grande/amplio/espacioso" ‚Üí ambiente/espacio
   ‚úì "porci√≥n peque√±a/chica/escasa" ‚Üí comida/porciones
   ‚úì "lugar peque√±o/chico/reducido" ‚Üí ambiente/espacio

3. EVIT√Å fragmentaci√≥n innecesaria:
   ‚úì CORRECTO: servicio + personal (menciones: 35)
   ‚úó INCORRECTO: servicio + atencion (18), servicio + atencion_amable (5), servicio + trato (9)
   
4. US√ÅS sub-aspectos GENERALES, NO ultra-espec√≠ficos:
   ‚úì S√ç: servicio + velocidad (incluye r√°pido Y lento, el sentiment indica si es positivo/negativo)
   ‚úì S√ç: servicio + personal (incluye amabilidad, trato, atenci√≥n)
   ‚úì S√ç: comida + porciones (incluye grande Y chico, el sentiment indica satisfacci√≥n)
   ‚úó NO: servicio + velocidad_rapida, servicio + velocidad_lenta (redundante con sentiment)

5. VOCABULARIO ESTANDARIZADO (sub-aspectos GENERALES y CONSOLIDADOS):
   
   SERVICIO:
   - personal (trato, amabilidad, cordialidad, "el/la chico/a", "los/las chicos/as", atento, mala onda)
   - velocidad (r√°pido, lento, demora, eficiente, espera larga)
   - profesionalismo (experiencia, conocimiento, capacitaci√≥n)
   
   COMIDA:
   - sabor (rico, delicioso, sabroso, mal sabor, ins√≠pido)
   - temperatura (fr√≠o, caliente, tibio)
   - frescura (fresco, pasado, viejo)
   - presentacion (visual, plato, montaje)
   - calidad (ingredientes, productos, calidad general)
   - porciones (grande, chica, abundante, escasa - la COMIDA, NO el personal)
   
   AMBIENTE:
   - ruido (ruidoso, bullicio, tranquilo, m√∫sica alta)
   - iluminacion (luz, oscuro, luminoso, tenue)
   - decoracion (estilo, deco, lindo, feo)
   - limpieza (limpio, sucio, descuidado)
   - espacio (amplio, chico, grande, peque√±o - el LUGAR, NO el personal)
   
   PRECIO:
   - valor (relaci√≥n calidad-precio, vale la pena, caro, barato, accesible, costoso)

6. Si NO hay sub-aspecto claro √∫til, d√©jalo vac√≠o o us√° "general"

RECORD√Å: Prioriz√° CONSOLIDACI√ìN sobre fragmentaci√≥n. Es mejor tener pocos sub-aspectos con muchas menciones que muchos sub-aspectos con pocas menciones cada uno.
`.trim();
// === Utilidades ===
function sleep(ms) {
  return new Promise((r)=>setTimeout(r, ms));
}
function sanitizeReviewText(text) {
  // Sanitizar texto para evitar problemas con JSON
  return text.replace(/\\/g, '\\\\') // Escapar backslashes primero
  .replace(/"/g, '\\"') // Escapar comillas dobles
  .replace(/\n/g, ' ') // Reemplazar saltos de l√≠nea con espacio
  .replace(/\r/g, ' ') // Reemplazar retornos de carro
  .replace(/\t/g, ' ') // Reemplazar tabs
  // eslint-disable-next-line no-control-regex
  .replace(/[\u0000-\u001F]/g, '') // Remover caracteres de control (intencional)
  .trim();
}
function truncateReviewText(text) {
  const sanitized = sanitizeReviewText(text);
  if (sanitized.length <= MAX_REVIEW_TEXT_LENGTH) return sanitized;
  return sanitized.slice(0, MAX_REVIEW_TEXT_LENGTH) + "...";
}
function normalizeProvider(p) {
  if (!p) return "unknown";
  const lower = p.toLowerCase();
  if (lower.includes("google")) return "google";
  if (lower.includes("trip")) return "tripadvisor";
  return lower;
}
function buildProviderBuckets(reviews) {
  const groups = {};
  for (const r of reviews){
    const key = normalizeProvider(r.provider);
    (groups[key] ??= []).push(r);
  }
  return {
    preferredMaxPerProvider: Math.max(1, Math.round(ANALYZE_BATCH_SIZE * MAX_PER_PROVIDER_RATIO)),
    groups
  };
}
function takeBatch(b, batchSize) {
  const result = [];
  const providers = Object.keys(b.groups).filter((k)=>b.groups[k].length > 0);
  if (!providers.length) return result;
  const gQ = b.groups["google"] ?? [];
  const tQ = b.groups["tripadvisor"] ?? [];
  const gQuota = Math.min(gQ.length, Math.round(batchSize * MAX_PER_PROVIDER_RATIO));
  const tQuota = Math.min(tQ.length, Math.round(batchSize * (1 - MAX_PER_PROVIDER_RATIO)));
  if (gQuota > 0) result.push(...gQ.splice(0, gQuota));
  if (tQuota > 0) result.push(...tQ.splice(0, tQuota));
  const ordered = providers.filter((p)=>p !== "google" && p !== "tripadvisor").sort((a, b2)=>b.groups[b2].length - b.groups[a].length);
  const fillQueues = [
    gQ,
    tQ,
    ...ordered.map((p)=>b.groups[p])
  ];
  for (const q of fillQueues){
    while(result.length < batchSize && q.length > 0)result.push(q.shift());
    if (result.length >= batchSize) break;
  }
  return result;
}
// === Estimaci√≥n de tokens para pacing (aprox 4 chars/token) ===
function estTokensFromChars(chars) {
  return Math.ceil(chars / 4);
}
function estimateBatchTokens(batch) {
  const sys = SYSTEM_PROMPT.length;
  const userPayload = JSON.stringify({
    analyses: batch.map((i)=>({
        review_id: i.id,
        text: truncateReviewText(i.text)
      }))
  }).length;
  const overhead = 1200; // margen por schema/serializaci√≥n
  return estTokensFromChars(sys + userPayload + overhead) + MAX_OUTPUT_TOKENS;
}
// === Respeta sugerencias de rate limit por respuesta (headers) ===
async function respectRateLimitHints(res) {
  const remReq = Number(res.headers.get("x-ratelimit-remaining-requests"));
  const resetReq = Number(res.headers.get("x-ratelimit-reset-requests"));
  if (Number.isFinite(remReq) && remReq <= 1) {
    const waitMs = Number.isFinite(resetReq) ? Math.max(resetReq * 1000, OPENAI_BACKOFF_BASE_MS) : OPENAI_BACKOFF_BASE_MS;
    console.warn(`‚è±Ô∏è Requests casi agotados. Esperando ${waitMs}ms`);
    await sleep(waitMs);
  }
  const remTok = Number(res.headers.get("x-ratelimit-remaining-tokens"));
  const resetTok = Number(res.headers.get("x-ratelimit-reset-tokens"));
  if (Number.isFinite(remTok) && remTok <= 1000) {
    const waitMs = Number.isFinite(resetTok) ? Math.max(resetTok * 1000, OPENAI_BACKOFF_BASE_MS) : OPENAI_BACKOFF_BASE_MS;
    console.warn(`‚è±Ô∏è Tokens casi agotados. Esperando ${waitMs}ms`);
    await sleep(waitMs);
  }
}
// === Backoff exponencial con jitter y soporte de Retry-After ===
function calculateBackoff(attempt, retryAfterHeader) {
  if (retryAfterHeader) {
    const s = Number(retryAfterHeader);
    if (Number.isFinite(s)) return Math.min(s * 1000, OPENAI_BACKOFF_MAX_MS);
  }
  const exp = OPENAI_BACKOFF_BASE_MS * Math.pow(2, attempt);
  const jitter = Math.random() * 250;
  return Math.min(exp + jitter, OPENAI_BACKOFF_MAX_MS);
}
// === Llamada a OpenAI con pacing proactivo (RPM/TPM) ===
async function callOpenAIBatch(batch, attempt = 0) {
  // Pacing previo para no golpear la ventana
  const est = estimateBatchTokens(batch);
  const minMsByTPM = Math.ceil(est / OPENAI_TARGET_TPM * 60_000);
  const minMsByRPM = Math.ceil(1 / OPENAI_TARGET_RPM * 60_000);
  const preWait = Math.max(minMsByTPM, minMsByRPM);
  if (preWait > 0) await sleep(preWait);
  const body = {
    model: OPENAI_MODEL,
    temperature: 0,
    response_format: {
      type: "json_schema",
      json_schema: batchResponseSchema
    },
    max_tokens: MAX_OUTPUT_TOKENS,
    messages: [
      {
        role: "system",
        content: SYSTEM_PROMPT
      },
      {
        role: "user",
        content: `Analiz√° TODAS las siguientes ${batch.length} reviews y devolv√© UN an√°lisis por cada una en el array 'analyses':\n\n` + JSON.stringify({
          analyses: batch.map((it)=>({
              review_id: it.id,
              text: truncateReviewText(it.text)
            }))
        })
      }
    ]
  };
  try {
    const response = await fetch(OPENAI_URL, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(body)
    });
    if (response.status === 429 || response.status === 503) {
      if (attempt >= OPENAI_MAX_RETRIES) {
        const detail = await response.text();
        throw new Error(`OpenAI rate limit tras ${OPENAI_MAX_RETRIES} reintentos: ${detail}`);
      }
      const delay = calculateBackoff(attempt, response.headers.get("retry-after"));
      console.warn(`‚ö†Ô∏è Rate limit (${response.status}). Retry ${attempt + 1}/${OPENAI_MAX_RETRIES} en ${delay}ms`);
      await sleep(delay);
      return callOpenAIBatch(batch, attempt + 1);
    }
    if (!response.ok) {
      const t = await response.text();
      throw new Error(`OpenAI error ${response.status}: ${t}`);
    }
    const data = await response.json();
    // Chat Completions API siempre devuelve en choices[0].message.content
    const content = data?.choices?.[0]?.message?.content;
    if (!content) {
      console.error("‚ùå Respuesta OpenAI sin contenido:", JSON.stringify(data));
      throw new Error("No content received from OpenAI");
    }
    await respectRateLimitHints(response);
    // Parse JSON con mejor manejo de errores
    let parsed;
    try {
      parsed = JSON.parse(content);
    } catch (parseErr) {
      console.error("‚ùå Error parseando JSON de OpenAI:");
      console.error("Content (primeros 500 chars):", content.substring(0, 500));
      console.error("Parse error:", parseErr);
      throw new Error(`JSON parsing failed: ${parseErr instanceof Error ? parseErr.message : String(parseErr)}`);
    }
    if (!parsed || !Array.isArray(parsed.analyses)) {
      console.error("‚ùå Estructura inv√°lida:", JSON.stringify(parsed).substring(0, 200));
      throw new Error("Respuesta OpenAI inv√°lida: falta 'analyses'");
    }
    for (const item of parsed.analyses){
      if (item.overall_score !== undefined) {
        item.overall_score = Math.min(1, Math.max(0, Number(item.overall_score)));
      }
      if (item.overall_sentiment_confidence !== undefined) {
        item.overall_sentiment_confidence = Math.min(1, Math.max(0, Number(item.overall_sentiment_confidence)));
      }
      if (Array.isArray(item.aspects)) {
        item.aspects = item.aspects.map((aspect)=>({
            ...aspect,
            severity: aspect.severity !== undefined ? Math.min(3, Math.max(1, Number(aspect.severity))) : undefined,
            gap_to_five_contrib: aspect.gap_to_five_contrib !== undefined ? Math.min(1, Math.max(0, Number(aspect.gap_to_five_contrib))) : undefined
          }));
      }
    }
    if (POST_BATCH_DELAY_MS > 0) {
      await sleep(POST_BATCH_DELAY_MS);
    }
    return parsed;
  } catch (err) {
    if (attempt < OPENAI_MAX_RETRIES) {
      const delay = calculateBackoff(attempt);
      console.warn(`‚ö†Ô∏è Error OpenAI (intento ${attempt + 1}). Reintento en ${delay}ms`, err);
      await sleep(delay);
      return callOpenAIBatch(batch, attempt + 1);
    }
    throw err;
  }
}
// === Handler principal ===
Deno.serve(async (req)=>{
  if (req.method === "OPTIONS") {
    return new Response("ok", {
      headers: corsHeaders
    });
  }
  try {
    if (!OPENAI_API_KEY) {
      return new Response("OPENAI_API_KEY no configurado", {
        status: 500,
        headers: corsHeaders
      });
    }
    const { external_place_id, limit } = await req.json();
    if (!external_place_id) {
      return new Response("external_place_id requerido", {
        status: 400,
        headers: corsHeaders
      });
    }
    // 1) Traer rese√±as sin an√°lisis previos (sentiment/aspects null)
    const rawLimit = Number.isFinite(Number(limit)) ? Math.min(Math.max(parseInt(String(limit), 10), 1), MAX_ANALYZE_LIMIT) : DEFAULT_ANALYZE_LIMIT;
    // M√°x 5 lotes por invocaci√≥n para no saturar
    const parsedLimit = Math.min(rawLimit, ANALYZE_BATCH_SIZE * 5);
    const { data: reviews, error } = await admin.from("reviews").select("id, provider, review_text, original_review_text, sentiment, aspects, overall_score, overall_sentiment_confidence, gap_to_five, gap_reasons, critical_flags, executive_summary, action_items, staff_mentions").eq("external_place_id", external_place_id).or("sentiment.is.null,aspects.is.null,overall_score.is.null,overall_sentiment_confidence.is.null,gap_to_five.is.null,gap_reasons.is.null,critical_flags.is.null,executive_summary.is.null,action_items.is.null,staff_mentions.is.null").order("posted_at", {
      ascending: false,
      nullsFirst: false
    }).limit(parsedLimit);
    if (error) throw error;
    const pending = [];
    for (const row of reviews ?? []){
      const already = row.sentiment && row.aspects && row.overall_score !== null && row.overall_sentiment_confidence !== null && row.gap_to_five !== null && row.gap_reasons !== null && row.critical_flags !== null && row.executive_summary !== null && row.action_items !== null && row.staff_mentions !== null;
      if (already) continue;
      const textRaw = (row.review_text || row.original_review_text || "").trim();
      if (!textRaw) continue;
      pending.push({
        id: row.id,
        provider: normalizeProvider(row.provider),
        text: textRaw
      });
    }
    if (pending.length === 0) {
      return new Response(JSON.stringify({
        ok: true,
        analyzed: 0,
        total_reviews_found: 0,
        processed_reviews: []
      }), {
        headers: {
          ...corsHeaders,
          "content-type": "application/json"
        }
      });
    }
    
    console.log(`üìä Encontradas ${pending.length} reviews pendientes de an√°lisis`);
    
    const buckets = buildProviderBuckets(pending);
    let updated = 0;
    let iterations = 0;
    const processed_reviews = [];
    const debugSteps: string[] = [];
    
    while(true){
      iterations++;
      const batch = takeBatch(buckets, ANALYZE_BATCH_SIZE);
      debugSteps.push(`Iter${iterations}: takeBatch returned ${batch.length}`);
      console.log(`üîÑ takeBatch retorn√≥ ${batch.length} reviews`);
      if (batch.length === 0) {
        debugSteps.push(`Iter${iterations}: Batch vac√≠o, break`);
        console.log('‚ö†Ô∏è  Batch vac√≠o, saliendo del loop');
        break;
      }
      
      console.log(`üîÑ Procesando batch de ${batch.length} reviews`);
      debugSteps.push(`Iter${iterations}: Procesando ${batch.length} reviews`);
      
      try {
        const ai = await callOpenAIBatch(batch);
        debugSteps.push(`Iter${iterations}: OpenAI retorn√≥ ${ai?.analyses?.length || 0} an√°lisis (esperaba ${batch.length})`);
        console.log(`‚úÖ OpenAI respondi√≥ con ${ai?.analyses?.length || 0} an√°lisis`);
        
        const analyses = Array.isArray(ai?.analyses) ? ai.analyses : [];
        const map = new Map();
        for (const it of analyses)if (it?.review_id) map.set(String(it.review_id), it);
        
        console.log(`üìù Mapeadas ${map.size} an√°lisis por review_id`);
        
        // DEBUG: Si OpenAI no retorn√≥ todos los an√°lisis, loguear
        if (analyses.length < batch.length) {
          debugSteps.push(`‚ö†Ô∏è OpenAI NO retorn√≥ todos los an√°lisis: ${analyses.length}/${batch.length}`);
          console.warn(`‚ö†Ô∏è OpenAI retorn√≥ menos an√°lisis de los esperados: ${analyses.length}/${batch.length}`);
        }
        
        let saved_this_batch = 0;
        for (const review of batch){
          const analysis = map.get(review.id);
          if (!analysis) {
            debugSteps.push(`‚ö†Ô∏è review ${review.id.substring(0,8)} NO tiene analysis en map`);
            console.warn(`‚ö†Ô∏è  No se encontr√≥ an√°lisis para review ${review.id}`);
            continue;
          }
          const { sentiment = null, aspects = null, language = null, overall_score = null, overall_sentiment_confidence = null, gap_to_five = null, gap_reasons = null, critical_flags = null, executive_summary = null, action_items = null, staff_mentions = null } = analysis;
          const { error: updErr } = await admin.from("reviews").update({
            sentiment: sentiment ?? null,
            aspects: aspects ?? null,
            language: language ?? null,
            overall_score: overall_score ?? null,
            overall_sentiment_confidence: overall_sentiment_confidence ?? null,
            gap_to_five: gap_to_five ?? null,
            gap_reasons: gap_reasons ?? null,
            critical_flags: critical_flags ?? null,
            executive_summary: executive_summary ?? null,
            action_items: action_items ?? null,
            staff_mentions: staff_mentions ?? null
          }).eq("id", review.id);
          if (updErr) {
            debugSteps.push(`‚ùå Error guardando ${review.id.substring(0,8)}: ${updErr.message || 'unknown'}`);
            console.error(`‚ùå Error update ${review.id}:`, updErr);
            continue;
          }
          updated++;
          saved_this_batch++;
          processed_reviews.push({
            review_id: review.id,
            sentiment: sentiment ?? null,
            aspects_count: Array.isArray(aspects) ? aspects.length : 0,
            gap_to_five: gap_to_five ?? null,
            overall_score: overall_score ?? null
          });
          console.log(`‚úÖ Analyzed ${review.id}: ${sentiment} (${Array.isArray(aspects) ? aspects.length : 0} aspects)`);
        }
        debugSteps.push(`Iter${iterations}: Guardadas ${saved_this_batch} reviews en BD`);
      } catch (batchErr) {
        console.error("‚ùå Error procesando batch:", batchErr);
        console.error("Stack:", batchErr instanceof Error ? batchErr.stack : 'No stack');
        // No hacer continue aqu√≠ - lanzar el error para que el usuario lo vea
        throw batchErr;
      }
    }
    console.log(`üèÅ Finalizando: ${updated} analizadas de ${pending.length} encontradas`);
    
    // DEBUG: Agregar info para diagnosticar
    const debugInfo = {
      iterations,
      buckets_providers: Object.keys(buckets.groups),
      buckets_sizes_after: Object.fromEntries(Object.entries(buckets.groups).map(([k, v]) => [k, v.length])),
      analyze_batch_size: ANALYZE_BATCH_SIZE,
      steps: debugSteps
    };
    
    return new Response(JSON.stringify({
      ok: true,
      analyzed: updated,
      total_reviews_found: pending.length,
      processed_reviews,
      debug: debugInfo
    }), {
      headers: {
        ...corsHeaders,
        "content-type": "application/json"
      }
    });
  } catch (e) {
    console.error("Error in analyze-reviews function:", e);
    const msg = e instanceof Error ? e.message : JSON.stringify(e);
    return new Response(JSON.stringify({
      ok: false,
      error: msg
    }), {
      status: 500,
      headers: corsHeaders
    });
  }
});
